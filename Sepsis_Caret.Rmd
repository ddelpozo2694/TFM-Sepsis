---
title: "Entrenamiento con datos desbalanceados"
author: "David del Pozo Granados"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
    toc_float:
      collapsed: no
    number_sections: yes
    theme: cosmo
editor_options: 
  markdown: 
    wrap: 72
---

## Lectura de datos

En primer lugar cargaremos la libería caret y borraremos los que
tengamos actualmente en el espacio de trabajo.

```{r}
rm(list = ls())
```

```{r}
library(dplyr) # Para la manipulación de datos
library(caret) # Para el entrenamiento del modelo
library(purrr) # Para programación funcional
library(pROC) # Para cálculos de Área Bajo la Curva
library(PRROC) # Para cálculos de la gráfica precision-recall
library(DMwR)
```

Posteriormente, leeremos los datos de entrenamiento, test y validación
que hemos convertido de Pkl a Csv para poder tratarlos con el paquete
caret. Quitaremos la primera columna de cada conjunto de datos, puesto
que es simplemente un identificador del paciente que no nos ofrece
información relevantes para el entrenamiento de los modelos.

```{r}

test_data <- read.csv("csv_data/linear_interpolation/test_data_ML.csv")
test_data <- test_data[,-1]
train_data <- read.csv("csv_data/linear_interpolation/train_data_ML.csv")
train_data <- train_data[,-1]
val_data <- read.csv("csv_data/linear_interpolation/val_data_ML.csv")
val_data <- val_data[,-1]


test_data_eti <- read.csv("csv_data/linear_interpolation/test_data_etiqueta.csv")
test_data_eti <- test_data_eti[,-1]
train_data_eti <- read.csv("csv_data/linear_interpolation/train_data_etiqueta.csv")
train_data_eti <- train_data_eti[,-1]
val_data_eti <- read.csv("csv_data/linear_interpolation/val_data_etiqueta.csv")
val_data_eti <- val_data_eti[,-1]
```

En este procesamiento elegimos el subconjunto de datos que queremos usar
en función del número de horas. Si elegimos por ejemplo 3 horas,
tendremos 4 tomas de datos para cada una de las 44 medidas (3 horas +
onset)

```{r}

n_horas <- 24 #Elegimos el número de horas antes de onset que elegimos.
valores <- c()
i<-1

while(i<=44){
  valores_aux <- c((i*49-n_horas):(i*49))
  valores <- c(valores,valores_aux)
  valores_aux <- c()
  i <- i+1
}
```

A continuación, también quitaremos las medidas para las horas que no
queremos, es decir, desde la hora posterior elegida en n_horas hasta 49.

```{r}
test_data <- test_data[,valores]
train_data <- train_data[,valores]
val_data <- val_data[,valores]
```

Añadimos las etiquetas al conjunto de datos de entrenamiento y
factorizamos las etiquetas que indican con un 1 si el paciente
finalmente se le detectó sepsis o con un 0 en caso contrario.

```{r}
train_data<- cbind(train_data,train_data_eti)
test_data<- cbind(test_data,test_data_eti)
val_data<- cbind(val_data,val_data_eti)

test_data$test_data_eti<- factor(test_data$test_data_eti, levels=c(1,0),labels=c("SI","NO"))
train_data$train_data_eti<-factor(train_data$train_data_eti, levels=c(1,0),labels=c("SI","NO"))
val_data$val_data_eti<- factor(val_data$val_data_eti, levels=c(1,0),labels=c("SI","NO"))

```

Comprobamos cuantos pacientes tienen o no Sepsis en nuestros tres
conjuntos de datos:

**Conjunto de datos de entrenamiento**

```{r}
# Valor entero
table(train_data$train_data_eti)

# Valor porcentual
prop.table(table(train_data$train_data_eti))

```

```{r}
# Valor entero
table(smote_train_data$train_data_eti)

# Valor porcentual
prop.table(table(smote_train_data$prueba_train_data_eti))
```

**Conjunto de datos de test**

```{r}
# Valor entero
table(test_data$test_data_eti)

# Valor porcentual
prop.table(table(test_data$test_data_eti))

```

**Conjunto de datos de validación**

```{r}
# Valor entero
table(val_data$val_data_eti)

# Valor porcentual
prop.table(table(val_data$val_data_eti))

```

Creamos una función de control con los siguientes parámetros: -
**Método**: validación cruzada - **Tamaño fold**: 10 - **Guardar
predicciones**: TRUE - **Modo Verbose**: FALSE - Finalmente, el
parámetro summaryFunction y classProbs deben indicar que queremos
calcular curvas ROC y para ello nuestro modelo debe proporcionar no solo
predicción de clase sino probabilidad de la predicción: -
**summaryFunction** = twoClassSummary, - **classProbs** = TRUE

```{r}
ctrl <- trainControl(method = "repeatedcv",
                     number = 10,
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

Entrenamos los distintos modelos basados en algoritmos de clasificación
que hemos seleccionado y que nos ofrece el paquete caret:

-   **KNN**
-   **LOGIT_BOOST**
-   **GLMBOOST**
-   **RPART**
-   **CTREE2**
-   **NAIVE BAYES**
-   **XGBTree**
-   **SVMLinear2**

```{r}
#ENTRENAMOS MODELO KNN

mod_knn <- train(train_data_eti~.,
                 data = train_data,
                 method = "knn",
                  trControl = ctrl)

save(mod_knn, file="Modelos_Entrenamiento24h/mod_knn.RData")
```

```{r}
#ENTRENAMOS MODELO LOGISTIC REGRESSION
 mod_LogitBoost <- train(
   train_data_eti~.,
  data = train_data,
   method = "LogitBoost",
                  trControl = ctrl)
save(mod_LogitBoost, file="Modelos_Entrenamiento24h/mod_LogitBoost.RData")
```

```{r}
#ENTRENAMOS MODELO GLMBOOST
 
mod_glmboost <- train(   train_data_eti~.,
                            data = train_data,
                             method = "glmboost",
                  trControl = ctrl)

save(mod_glmboost, file="Modelos_Entrenamiento24h/mod_glmboost.RData")

```

```{r}
#ENTRENAMOS MODELO RPART
mod_rpart <- train(   train_data_eti~.,
                            data = train_data,
                             method = "rpart", 
                  trControl = ctrl)

save(mod_rpart, file="Modelos_Entrenamiento24h/mod_rpart.RData")
```

```{r}
#ENTRENAMOS MODELO CTREE2
mod_ctree2<- train(   train_data_eti~.,
                            data = train_data,
                             method = "ctree2",
                  trControl = ctrl)

save(mod_ctree2, file="Modelos_Entrenamiento24h/mod_ctree2.RData")
```

```{r}
 #ENTRENAMOS MODELO NAIVE BAYES
mod_nb <- train(   train_data_eti~.,
                            data = train_data,
                             method = "naive_bayes",
                  trControl = ctrl)

save(mod_nb, file="mod_nb.RData")
```

```{r}
#ENTRENAMOS MODELO XGBTree 
mod_xgbTree <- train(   train_data_eti~.,
                            data = train_data,
                            method = "xgbTree",
                         trControl = ctrl,
                         verbose = FALSE,
                         verbosity = 0)

save(mod_xgbTree, file="Modelos_Entrenamiento24h/mod_xgbTree.RData")
```

```{r}
#ENTRENAMOS MODELO svmLinear2
mod_svmLinear2 <- train(   train_data_eti~.,
                          data = train_data,
                            method = "svmLinear2", 
                            trControl = ctrl)

save(mod_svmLinear2, file="Modelos_Entrenamiento24h/mod_svmLinear2.RData")
```

**Entrenamiento de modelos con expandgrid para ver la mejor combinación
de parámetros**

```{r}
#ENTRENAMOS MODELO KNN

mod_knn_tune <- train(train_data_eti~.,
                 data = train_data,
                 method = "knn",
                 tuneGrid = expand.grid(k = c(2,5,10)),
                  trControl = ctrl)

save(mod_knn_tune, file="Modelos_Entrenamiento24h_tune/mod_knn_tune.RData")
```

```{r}
#ENTRENAMOS MODELO LOGISTIC REGRESSION
 mod_LogitBoost_tune <- train(
   train_data_eti~.,
  data = train_data,
   method = "LogitBoost",
  tuneGrid = expand.grid(nIter = c(2,5,11)),
                  trControl = ctrl)
save(mod_LogitBoost_tune, file="Modelos_Entrenamiento24h_tune/mod_LogitBoost_tune.RData")
```

```{r}
#ENTRENAMOS MODELO CTREE2
mod_ctree2_tune<- train(   train_data_eti~.,
                            data = train_data,
                             method = "ctree2",
                           tuneGrid = expand.grid(maxdepth=c(5,10),mincriterion=c(0.1,0.5)),
                  trControl = ctrl)

save(mod_ctree2_tune, file="Modelos_Entrenamiento24h_tune/mod_ctree2_tune.RData")
```

```{r}
 #ENTRENAMOS MODELO NAIVE BAYES
mod_nb_tune <- train(   train_data_eti~.,
                            data = train_data,
                             method = "naive_bayes",
                        tuneGrid = expand.grid(laplace=c(0,0.5), usekernel = TRUE, adjust=c(0.5,1.0)),
                  trControl = ctrl)

save(mod_nb_tune, file="Modelos_Entrenamiento24h_tune/mod_nb_tune.RData")
```

```{r}
#ENTRENAMOS MODELO XGBTree 
mod_xgbTree_tune <- train(   train_data_eti~.,
                            data = train_data,
                            method = "xgbTree",
                            tuneGrid = expand.grid(max_depth = c(1,2) ,
                          eta = c(0.5,1),
                          nrounds=c(300,100),
                          gamma = 0,
                          colsample_bytree= 1,
                          min_child_weight = 1,
                          subsample = 1),
                         trControl = ctrl,
                         verbose = FALSE,
                         verbosity = 0)

save(mod_xgbTree_tune, file="Modelos_Entrenamiento24h_tune/mod_xgbTree_tune.RData")
```

Se irá añadiendo a una lista los distintos modelos que hemos ido
entrenando y estos se pasarán por un remuestreo con la función
resamples:

```{r}
Modelos_Entrenados <- list(
   knn = mod_knn,
   glmboost = mod_glmboost,
   rpart = mod_rpart,
   ctree2 = mod_ctree2,
   naive_bayes = mod_nb,
   xgbTree = mod_xgbTree,
   svmLinear2 = mod_svmLinear2,
   LogitBoost = mod_LogitBoost
   )


resamples <- resamples(Modelos_Entrenados)

```

```{r}
Modelos_Entrenados_tune <- list(
   xgbTree_tune = mod_xgbTree_tune,
   nb_tune = mod_nb_tune,
   knn_tune = mod_knn_tune,
   LogitBoost_tune = mod_LogitBoost_tune,
   ctree2_tune = mod_ctree2_tune
   )


resamples_tune <- resamples(Modelos_Entrenados_tune)

```

Haremos una predicción de los modelos anteriormente entrenados, usando
el conjunto de datos de validación para calculara la precisión de los
modelos (Accuracy):

```{r}

#Confusion Matriz para modelo knn
knn_pred <- predict(mod_knn, test_data)
confusionMatrix(knn_pred ,test_data$test_data_eti,mode="everything")


#Confusion Matriz para modelo glmboost
glmboost_pred <- predict(mod_glmboost, test_data)
confusionMatrix(glmboost_pred ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo rpart
rpart_pred <- predict(mod_rpart, test_data)
confusionMatrix(rpart_pred ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo ctree2
ctree2_pred <- predict(mod_ctree2, test_data)
confusionMatrix(ctree2_pred ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo naive bayes
nb_pred <- predict(mod_nb, test_data)
confusionMatrix(nb_pred  ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo xgbTree
xgbTree_pred <- predict(mod_xgbTree, test_data)
confusionMatrix(xgbTree_pred  ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo svmLinear2
svmLinear2_pred <- predict(mod_svmLinear2, test_data)
confusionMatrix(svmLinear2_pred  ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo LogitBoost
LogitBoost_pred <- predict(mod_LogitBoost, test_data)
confusionMatrix(LogitBoost_pred  ,test_data$test_data_eti,mode="everything")
```

**Confusion Matrix Modelos Tune**

```{r}

#Confusion Matriz para modelo knn
knn_pred_tune <- predict(mod_knn_tune, test_data)
confusionMatrix(knn_pred_tune ,test_data$test_data_eti,mode="everything")


#Confusion Matriz para modelo naive bayes
nb_pred_tune <- predict(mod_nb_tune, test_data)
confusionMatrix(nb_pred_tune  ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo LogitBoost
LogitBoost_pred_tune <- predict(mod_LogitBoost_tune, test_data)
confusionMatrix(LogitBoost_pred_tune  ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo xgbTree
xgbTree_pred_tune <- predict(mod_xgbTree_tune, test_data)
confusionMatrix(xgbTree_pred_tune  ,test_data$test_data_eti,mode="everything")

#Confusion Matriz para modelo ctree2_
ctree2_pred_tune <- predict(mod_ctree2_tune, test_data)
confusionMatrix(ctree2_pred_tune,test_data$test_data_eti,mode="everything")
```

Mostramos gráficamente los modelos y los compararemos para ver de manera
visual cual es el mejor modelo de predicción temprana de sepsis para
este conjunto de datos. Con el siguiente código mostraremos el área bajo
la curva ROC, la sensibilidiad y la especificidad.

```{r}

summary(resamples)
bwplot(resamples)
dotplot(resamples)


```

```{r}
summary(resamples_tune)
bwplot(resamples_tune)
dotplot(resamples_tune)
```

A continuación, escribimos una función para el cálculo del Área Bajo la
Curva Precision-Recall

```{r}
calc_auprc <- function(model, data){
  
  index_class2 <- data$train_data_eti == "SI"
  index_class1 <- data$train_data_eti == "NO"
  
  predictions <- predict(model, data, type = "prob")
  
  pr.curve(predictions$SI[index_class2], predictions$SI[index_class1], curve = TRUE)
  
}
```

```{r}
model_list_pr <- Modelos_Entrenados_tune  %>%
  map(calc_auprc, data = train_data)
model_list_pr %>%
  map(function(the_mod) the_mod$auc.integral)
```

Mostramos gráficamos los resultamos de AUPRC para los distintos modelos

```{r}

results_list_pr <- list(NA)
num_mod <- 1
for(the_pr in model_list_pr){
  
  results_list_pr[[num_mod]] <- data_frame(recall = the_pr$curve[, 1],
                                           precision = the_pr$curve[, 2],
                                           model = names(model_list_pr)[num_mod])
  
  num_mod <- num_mod + 1
  
}
results_df_pr <- bind_rows(results_list_pr)
#custom_col <- c("#000000", "#009E73", "#0072B2", "#D55E00","#CC79A7","#CCBB79","#AB0A28","#7FCC79")
custom_col <- c("#000000", "#009E73", "#0072B2", "#D55E00","#AB0A28")

ggplot(aes(x = recall, y = precision, group = model), data = results_df_pr) +
  geom_line(aes(color = model), size = 1) +
  scale_color_manual(values = custom_col) +
  geom_abline(intercept = sum(test_data$Class == "Class2")/nrow(test_data),
              slope = 0, color = "gray", size = 1) +
  theme_bw()
```
